{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DD5437A3A0747FAA26055E059BA0D2F",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 推荐评论展示任务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5EEC167049B645148A62054DFD83C614",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 任务描述 \n",
    "\n",
    "本次推荐评论展示任务的目标是从真实的用户评论中，挖掘合适作为推荐理由的短句。点评软件展示的推荐理由具有长度限制，而真实用户评论语言通顺、信息完整。综合来说，两者都具有用户情感的正负向，但是展示推荐理由的内容相关性高于评论，需要较强的文本吸引力。一些真实的推荐理由如下图所示：\n",
    "\n",
    "![推荐理由](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/textcls_pic/apppic.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3A7700881EB490CAA5AF26AF1C83E94",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 数据集\n",
    "\n",
    "本次推荐评论展示任务所采用的数据集是点评软件中，用户中文评论的集合。\n",
    "\n",
    "\n",
    "## 数据样例\n",
    "本次任务要求将这些评论分为两类，即“展示”和“不展示”，分别以数字1和0作为标注，如下图所示：\n",
    "\n",
    "\n",
    "![数据样例](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/textcls_pic/dataexp.png)\n",
    "\n",
    "## 文档说明 \n",
    "\n",
    "\n",
    "数据集文件分为训练集和测试集部分，对应文件如下：\n",
    "\n",
    "- 带标签的训练数据：`train_shuffle.txt` \n",
    "- 不带标签的测试数据：`test_handout.txt`\n",
    "\n",
    "注意，`test_handout.txt`文件的行索引从0开始，对应于ID一列，评论内容为“展示”的预测概率应于Prediction一列。\n",
    "\n",
    "需要注意的是，由于数据在标注时存在主观偏好，标记为“不展示”（0）的评论不一定是真正的负面评论，反之亦然。但是这种情况的存在，不会对任务造成很大的歧义，通过基准算法我们可以在测试集上实现很高的性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "044BF1D9750745F7AB4449F7EECB0297",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 任务拆解\n",
    "\n",
    "推荐评论展示任务需要对数据集中的评论文本文件进行处理，传统的学习方式流程为：\n",
    "\n",
    "![学习流程](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/textcls_pic/method.png)\n",
    "\n",
    "对于以上的任务，近年来兴起的深度学习算法都可以实现：\n",
    "\n",
    "![学习流程](https://boyuai.oss-cn-shanghai.aliyuncs.com/disk/YouthAI%E7%A7%8B%E5%AD%A3%E6%80%9D%E7%BB%B4%E7%8F%AD-%E4%B8%8A%E8%AF%BE%E8%A7%86%E9%A2%91/textcls_pic/deepmethod.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FFAB27CCB1CC4391B000A3E0D20792A9",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# 评估说明\n",
    "\n",
    "## 评价指标\n",
    "\n",
    "本次任务采用 [AUC（Area Under Curve)](https://baike.baidu.com/item/AUC/19282953) 作为模型的评价标准。\n",
    "\n",
    "## 在线评估\n",
    "\n",
    "评估函数首先会验证选手提交的预测结果文件是否符合要求，主要验证了以下要求:\n",
    "\n",
    "1. 提交的预测文件是否存在重复ID\n",
    "2. 提交的预测文件ID是否与测试集文件ID不匹配\n",
    "3. 提交的预测文件Prediction列是否存在整数（auc测评要求选手提供的是概率值，而非分类结果0或1）\n",
    "\n",
    "通过验证后的文件会用以AUC为测评指标的函数进行计算评估。\n",
    "\n",
    "\n",
    "## 文件格式\n",
    "\n",
    "由于测评脚本已经统一，为保证脚本的顺利运行，在进行测评时，要求选手提交的`预测文件`拥有规范的字段名和字段格式，预测文件具体要求如下：\n",
    "\n",
    "| NO | 字段名称 | 数据类型 | 字段描述 |\n",
    "| -------- | -------- | -------- | -------- |\n",
    "| 1    | ID     | int    | ID序列     |\n",
    "| 2    | Prediction   | float     | 预测结果（概率值）   |\n",
    "\n",
    "正确格式的提交文件样例: `submission_random.csv`。\n",
    "\n",
    "## 基准算法\n",
    "\n",
    "本次任务采用不同的基准算法，获得模型的AUC如下：\n",
    "- 随机基准算法AUC：0.51209\n",
    "- 弱基准算法AUC：0.85107\n",
    "- 强基准算法AUC：0.94452\n",
    "在评估时，以弱基准算法的AUC作为达标线。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1E67455E9B3D49E6864F5A8C971CFD87",
    "jupyter": {},
    "mdEditEnable": false,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 终审评估\n",
    "\n",
    "本次任务的终审评估将挑选在评分指标位于前10名的同学进行项目报告撰写，以描述模型、算法及实验等相关内容和结果，报告排版要求届时发布。\n",
    "\n",
    "除此以外，为保证竞赛的公平性，进入终审评估的同学需要提交项目代码，由助教进行模型的有效性验证。\n",
    "\n",
    "如发现实验结果有较大差异，或者模型无法复现等问题，组委会将取消营员本次14天陪你挑战《动手学深度学习》的结营资格，并且进行公示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "id": "F0F0B63406E048809614C9924479D2C6",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import os\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "import random\n",
    "import matplotlib.pyplot as pyplot\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "import torchtext.vocab as Vocab\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import nltk\n",
    "import jieba\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "id": "2FCE8C95515E4CFC8711F2BD7ABBEE8E",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data_train.csv\", encoding='gbk')\n",
    "data_train.rename(columns={'0':'label', '1':'comment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>酸菜鱼不错</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>轻食素食都是友善的饮食方式</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>完爆中午吃的农家乐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>烤鱼很入味</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>有种入口即化的感觉</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        comment\n",
       "0      0          酸菜鱼不错\n",
       "1      0  轻食素食都是友善的饮食方式\n",
       "2      0      完爆中午吃的农家乐\n",
       "3      1          烤鱼很入味\n",
       "4      0      有种入口即化的感觉"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "id": "136163C777674B7B822FDA9450ABC597",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_train['length'] = data_train['comment'].apply(lambda x: len(x))\n",
    "data_train['length'].hist()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "id": "A9DD14EDA7C2406082EB301991FAF8E6",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"data_test.csv\", encoding='gbk')\n",
    "data_test.rename(columns={'0':'comment'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>理由很简单</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>蘸着花生酱吃非常美味</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>味道奶香味恰到好处</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>面包片烤的恰到好处</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>属于简单经济型</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment\n",
       "0       理由很简单\n",
       "1  蘸着花生酱吃非常美味\n",
       "2   味道奶香味恰到好处\n",
       "3   面包片烤的恰到好处\n",
       "4     属于简单经济型"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "id": "E7393D7D241548B18C688F342599AB53",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_comment_list = list(data_train['comment'])\n",
    "test_comment_list = list(data_test['comment'])\n",
    "train_label = list(data_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "id": "5AEE9C55CF464FD8AEF58A9D65494B2C",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(sentences, token='word'):\n",
    "    \"\"\"Split sentences into word or char tokens\"\"\"\n",
    "    if token == 'word':\n",
    "        return [jieba.lcut(sentence, cut_all=False) for sentence in sentences]\n",
    "    elif token == 'char':\n",
    "        return [list(sentence) for sentence in sentences]\n",
    "    else:\n",
    "        print('ERROR: unkown token type '+token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "id": "BC2135DCC9AD45E68A8B827E9D619A5D",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_tokenize = tokenize(train_comment_list, token='char')\n",
    "test_tokenize = tokenize(test_comment_list, token='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "id": "D6C6598F76734C9A8ADDD03093B242C3",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['酸', '菜', '鱼', '不', '错'],\n",
       " ['轻', '食', '素', '食', '都', '是', '友', '善', '的', '饮', '食', '方', '式'],\n",
       " ['完', '爆', '中', '午', '吃', '的', '农', '家', '乐'],\n",
       " ['烤', '鱼', '很', '入', '味'],\n",
       " ['有', '种', '入', '口', '即', '化', '的', '感', '觉']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenize[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "id": "1845B8DBD4504DF782FCD9FA76AE8C9D",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "counter = collections.Counter([word for sentence in train_comment_list for word in sentence])\n",
    "vocab = Vocab.Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "id": "4D354F59DAC347F18E2997454DAF55AD",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(tokenized_data, vocab):\n",
    "    '''\n",
    "    @params:\n",
    "        data: 同上，原始的读入数据\n",
    "        vocab: 训练集上生成的词典\n",
    "    @return:\n",
    "        features: 单词下标序列，形状为 (n, max_l) 的整数张量\n",
    "        labels: 情感标签，形状为 (n,) 的0/1整数张量\n",
    "    '''\n",
    "    max_l = 19 # 将每条评论通过截断或者补0，使得长度变成500\n",
    "    #从原理上面讲，其实可以不用文本进行等长的划分，但是为了训练方便，更好的并行化处理\n",
    "    def pad(x):\n",
    "        return x[:max_l] if len(x) > max_l else x + [0] * (max_l - len(x))\n",
    "    #将文本转换成 tensor.long的格式\n",
    "    features = torch.tensor([pad([vocab.stoi[word] for word in words]) for words in tokenized_data])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "id": "B1BA51F6C5D5439F827188B31D2E6978",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data =  preprocess(train_comment_list, vocab)\n",
    "test_data = preprocess(test_comment_list, vocab)\n",
    "train_label = torch.tensor(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "id": "E0D13E7C49B7454D83FB0E913175EAE1",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_all_set = Data.TensorDataset(train_data, train_label)\n",
    "#划分训练集合以及测试集合\n",
    "train_set, val_set = torch.utils.data.random_split(train_all_set, [int(0.9*len(data_train)), len(data_train)-int(0.9*len(data_train))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "id": "EE5C0105F54C4FBFBC9614E55542FD3A",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_iter = Data.DataLoader(train_set, batch_size, shuffle=True)\n",
    "val_iter = Data.DataLoader(val_set, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "id": "FF079393835C40F3A277037D3099CDD1",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, num_hiddens, num_layers):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: 在数据集上创建的词典，用于获取词典大小\n",
    "            embed_size: 嵌入维度大小\n",
    "            num_hiddens: 隐藏状态维度大小\n",
    "            num_layers: 隐藏层个数\n",
    "        '''\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size)\n",
    "        # encoder-decoder framework\n",
    "        # bidirectional设为True即得到双向循环神经网络\n",
    "        self.encoder = nn.LSTM(input_size=embed_size, \n",
    "                                hidden_size=num_hiddens, \n",
    "                                num_layers=num_layers,\n",
    "                                bidirectional=True)\n",
    "        self.decoder = nn.Linear(4*num_hiddens, 2) # 初始时间步和最终时间步的隐藏状态作为全连接层输入\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n",
    "        @return:\n",
    "            outs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n",
    "        '''\n",
    "        # 因为LSTM需要将序列长度(seq_len)作为第一维，所以需要将输入转置\n",
    "        embeddings = self.embedding(inputs) # (seq_len, batch_size, d)\n",
    "        embeddings = embeddings.transpose(0,1) # (seq_len, batch_size, d)\n",
    "        # rnn.LSTM 返回输出、隐藏状态和记忆单元，格式如 outputs, (h, c)\n",
    "        outputs, _ = self.encoder(embeddings) # (seq_len, batch_size, 2*h)\n",
    "        encoding =  torch.cat((outputs[0], outputs[-1]), -1) # (batch_size, 4*h)\n",
    "        outs = self.decoder(encoding) # (batch_size, 2)\n",
    "        return outs\n",
    "embed_size, num_hiddens, num_layers = 100, 64, 1\n",
    "net = BiRNN(vocab, embed_size, num_hiddens, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "id": "4CF37F68AF8A4EBFA4DE3967EDE8E32D",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_accuracy(data_iter, net, device=None):\n",
    "    if device is None and isinstance(net, torch.nn.Module):\n",
    "        device = list(net.parameters())[0].device \n",
    "    acc_sum, n = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            if isinstance(net, torch.nn.Module):\n",
    "                net.eval()\n",
    "                acc_sum += (net(X.to(device)).argmax(dim=1) == y.to(device)).float().sum().cpu().item()\n",
    "                net.train()\n",
    "            else:\n",
    "                if('is_training' in net.__code__.co_varnames):\n",
    "                    acc_sum += (net(X, is_training=False).argmax(dim=1) == y).float().sum().item() \n",
    "                else:\n",
    "                    acc_sum += (net(X).argmax(dim=1) == y).float().sum().item() \n",
    "            n += y.shape[0]\n",
    "    return acc_sum / n\n",
    "def train(train_iter, test_iter, net, loss, optimizer, device, num_epochs):\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    batch_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n",
    "        for X, y in train_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            l = loss(y_hat, y) \n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        test_acc = evaluate_accuracy(test_iter, net)\n",
    "        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n, test_acc, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "id": "7E73F6F22DE14F559871B4C81C58538F",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4092, train acc 0.803, test acc 0.871, time 1.4 sec\n",
      "epoch 2, loss 0.1322, train acc 0.893, test acc 0.876, time 1.3 sec\n",
      "epoch 3, loss 0.0752, train acc 0.911, test acc 0.884, time 1.3 sec\n",
      "epoch 4, loss 0.0477, train acc 0.925, test acc 0.874, time 1.3 sec\n",
      "epoch 5, loss 0.0326, train acc 0.937, test acc 0.885, time 1.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 5\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train(train_iter, val_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "id": "86F58782BDE544178CC47F2153898F35",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#采用text cnn进行分类\n",
    "class GlobalMaxPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalMaxPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        @params:\n",
    "            x: 输入，形状为 (batch_size, n_channels, seq_len) 的张量\n",
    "        @return: 时序最大池化后的结果，形状为 (batch_size, n_channels, 1) 的张量\n",
    "        '''\n",
    "        return F.max_pool1d(x, kernel_size=x.shape[2]) # kenerl_size=seq_len\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab, embed_size, kernel_sizes, num_channels):\n",
    "        '''\n",
    "        @params:\n",
    "            vocab: 在数据集上创建的词典，用于获取词典大小\n",
    "            embed_size: 嵌入维度大小\n",
    "            kernel_sizes: 卷积核大小列表\n",
    "            num_channels: 卷积通道数列表\n",
    "        '''\n",
    "        super(TextCNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(len(vocab), embed_size) # 参与训练的嵌入层\n",
    "        self.constant_embedding = nn.Embedding(len(vocab), embed_size) # 不参与训练的嵌入层\n",
    "        \n",
    "        self.pool = GlobalMaxPool1d() # 时序最大池化层没有权重，所以可以共用一个实例\n",
    "        self.convs = nn.ModuleList()  # 创建多个一维卷积层\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "            self.convs.append(nn.Conv1d(in_channels = 2*embed_size, \n",
    "                                        out_channels = c, \n",
    "                                        kernel_size = k))\n",
    "            \n",
    "        self.decoder = nn.Linear(sum(num_channels), 2)\n",
    "        self.dropout = nn.Dropout(0.5) # 丢弃层用于防止过拟合\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        '''\n",
    "        @params:\n",
    "            inputs: 词语下标序列，形状为 (batch_size, seq_len) 的整数张量\n",
    "        @return:\n",
    "            outputs: 对文本情感的预测，形状为 (batch_size, 2) 的张量\n",
    "        '''\n",
    "        embeddings = torch.cat((\n",
    "            self.embedding(inputs), \n",
    "            self.constant_embedding(inputs)), dim=2) # (batch_size, seq_len, 2*embed_size)\n",
    "        # 根据一维卷积层要求的输入格式，需要将张量进行转置\n",
    "        #transpose只能每次交换两维，而permute可以针对多维进行交换\n",
    "        embeddings = embeddings.permute(0, 2, 1) # (batch_size, 2*embed_size, seq_len)\n",
    "        encoding = torch.cat([\n",
    "            self.pool(F.relu(conv(embeddings))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        # encoding = []\n",
    "        # for conv in self.convs:\n",
    "        #     out = conv(embeddings) # (batch_size, out_channels, seq_len-kernel_size+1)\n",
    "        #     out = self.pool(F.relu(out)) # (batch_size, out_channels, 1)\n",
    "        #     encoding.append(out.squeeze(-1)) # (batch_size, out_channels)\n",
    "        # encoding = torch.cat(encoding) # (batch_size, out_channels_sum)\n",
    "        \n",
    "        # 应用丢弃法后使用全连接层得到输出\n",
    "        outputs = self.decoder(self.dropout(encoding))\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "id": "AEA6D745CE9849328A51ABF99AEF19F8",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size, kernel_sizes, nums_channels = 64, [3, 4, 5], [128, 128, 128]\n",
    "net = TextCNN(vocab, embed_size, kernel_sizes, nums_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "id": "2DBCD99CED26434897BDDB5F7F0DEBC3",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on  cuda\n",
      "epoch 1, loss 0.4013, train acc 0.823, test acc 0.891, time 1.4 sec\n",
      "epoch 2, loss 0.1436, train acc 0.881, test acc 0.890, time 1.3 sec\n",
      "epoch 3, loss 0.0828, train acc 0.898, test acc 0.885, time 1.4 sec\n",
      "epoch 4, loss 0.0543, train acc 0.911, test acc 0.894, time 1.3 sec\n",
      "epoch 5, loss 0.0385, train acc 0.923, test acc 0.878, time 1.3 sec\n",
      "epoch 6, loss 0.0277, train acc 0.933, test acc 0.896, time 1.3 sec\n",
      "epoch 7, loss 0.0211, train acc 0.942, test acc 0.891, time 1.3 sec\n",
      "epoch 8, loss 0.0168, train acc 0.949, test acc 0.889, time 1.3 sec\n",
      "epoch 9, loss 0.0138, train acc 0.952, test acc 0.896, time 1.3 sec\n",
      "epoch 10, loss 0.0109, train acc 0.959, test acc 0.898, time 1.3 sec\n"
     ]
    }
   ],
   "source": [
    "lr, num_epochs = 0.001, 10\n",
    "optimizer = torch.optim.Adam( net.parameters(), lr=lr)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "train(train_iter, val_iter, net, loss, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "id": "2F74FEB07A2E4E5785A03BA8FE2D5391",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangfuxin/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    test_pred = net(test_data.cuda())\n",
    "    test_pred = F.softmax(test_pred).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "id": "C187D3CD96BB458E86624FAD38E96D80",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 2828, 1: 1361})\n"
     ]
    }
   ],
   "source": [
    "test_label = test_pred.argmax(dim=1).numpy()\n",
    "print(collections.Counter(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "id": "35BAFA55B56342178195C0D77DB50B4E",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_pred = test_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "id": "B0791EB2583845E4B58F9E32F28623B1",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_random = pd.DataFrame({})\n",
    "submission_random['ID'] = range(test_pred.shape[0])\n",
    "submission_random['Prediction'] = test_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "id": "B4BF2E9F6DD5456891EFA795AB5C746A",
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_random.to_csv(\"submission_random.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78A0BF39737C4DF9807D4D1B13F05E7C",
    "jupyter": {},
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
